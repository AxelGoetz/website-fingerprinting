% TODO: Remove
\bibliography{../report.bib}

\section{Background Information, Related Work and Research}
In the following chapter, we further explore the motivation for undertaking the project,
analyse the current state of the project domain and outline the research that forms the basis for the rest of the report.

\subsection{The Problem}
As previously mentioned, the goal of this project is to automate the feature selection process for a website fingerprinting attack.
By this we mean that given a specific trace, our model should be able to produce a fixed-length vector that is a close representation of the respective trace.
However, before we delve into the details of the attack, we first need to gain a greater understanding of some concepts such as
onion routing, website fingerprinting in general and deep learning.

\subsubsection{Onion Routing}
To preserve privacy, we do not only need to obscure the content of a webpage but also hide who is taking to whom \cite{goldschlag1999onion}.
Tor achieves both of these by making use of a technique, called \textit{onion routing}, which is a very simple protocol that can be divided up into three phases:
connection setup, data movement and connection tear-down \cite{goldschlag1999onion}. We show how it works by taking a simple example of Alice trying to communicate with Bob.

\begin{enumerate}
  \item \textbf{Connection Setup:}
    \begin{itemize}
      \item Alice's Tor client obtains a list of Tor nodes from a directory server.
      \item Then Alice picks three random Tor nodes and labels them \textit{one, two} and \textit{three}.
      \item Alice communicates with the first node and shares a symmetric key.
      \item Next, Alice sends messages to the first node, which are then forwarded to the second node to share another symmetric key to the second node.
      \item Finally, Alice continues sending messages to the first node, which are forwarded to the second and finally to the third node to share the final symmetric key.
        What is important here is that we use a secure key-sharing algorithm such that only Alice and the respective node know the keys.
        Additionally, since all of the traffic is forwarded from the first node, the second and the third nodes do not know the identity of Alice.
    \end{itemize}

    \begin{figure}[h]
      \centering
      \includegraphics[width=0.75\textwidth]{tor_setup}
      \caption{An example of a connection setup for the onion routing protocol.}
      \label{fig:tor_setup}
    \end{figure}

  \item \textbf{Data Movement:}
    \begin{itemize}
      \item Before Alice can send any data, it first needs to encrypt it in different layers. By this we mean that first it encrypts the data \textit{(with Bob's address)}
        using the shared key from the third node. Next, it encrypts that data again \textit{(with the address of the third node)} using the key from the second node.
        Finally, as expected, it encrypts the data a final time \textit{(with the address of the second node)} using the shared key from the first node.

      \item Now Alice is ready to send the data to the first node.
      \item Once the first node received the data, it decrypts it using the shared key. This reveals the address to the second node.
        The key is here that the first node cannot see the data nor where it is going, since that is still encrypted.

      \item Next, the first node forwards the data that it just unencrypted to the second node. Again, this node decrypts the data, revealing the address to the third node
        but now it doesn't know what the data is, where the final destination is or where it originally came from.

      \item Lastly, the second node forwards the data to the third node. After encryption, this final node can see the data and where it is going but it does not know where it came from.
        So it forwards the data to Bob and not a single party should be able to know the data, the final destination and where it originally came from except for Alice and Bob.
    \end{itemize}

    Now we know why the protocol is called onion routing because it encrypts the data in multiple layers and at every node, one of the layers of the onion is peeled off \cite{tor_project2}.
    The key is that none of the nodes know the complete path that has been taken.

    \begin{figure}[h]
      \centering
      \includegraphics[width=0.75\textwidth]{tor_message_sending}
      \caption{Sending a message with the onion routing protocol.}
      \label{fig:tor_message_sending}
    \end{figure}

  \item \textbf{Connection Tear-down:} This can be initiated by any of the nodes or the client and the process is very straightforward.
    Either the client sends a request for a tear-down to the first node to remove any data on the connection (including the shared key), which is then forwarded to the other nodes.
    Or one of the nodes sends a tear-down message to both the previous node and the next node, which are then forwarded in both directions \cite{goldschlag1999onion}.

\end{enumerate}

Tor generally uses the same circuit for connections that happen within around 10 minutes after creating a circuit.
Later requests, however, are given a new circuit \cite{tor_project, tor_project2}.

\subsection{Related Work}

\subsubsection{Website Fingerprinting}

Website fingerprinting (WF) is the process of attempting to identify which web pages a specific client visits by analysing their traffic traces.
Hence, an attacker is considered to be \textit{local} . By this we mean that they can eavesdrop on the traffic between the client and the first Tor node, as shown in figure \ref{fig:threat_model}.
So it can be anyone from a person on the same network to an ISP.
The reason as to why the attacker has to be local is because in onion routing systems, it is the only place in the network where you still know
the true identity of the client.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\textwidth]{threat_model}
  \caption{Threat model for a simple website fingerprinting attack.}
  \label{fig:threat_model}
\end{figure}

In general, the attack is as follows. The attacker first collects a dataset that contains packet traces for loading several web pages.
In practice, these web pages are the ones that an attacker is interested in monitoring.
From those traces, the attacker extracts a fixed number of features, the so-called \textit{fingerprint}.
Next, it uses those fingerprints to train some sort of model \textit{(often a machine learning model)} to find patterns in the data.
The attacker observes packet traces, generated by the client, and uses the model to classify which web pages the user is visiting.
Therefore, an attack is essentially a classification problem, where you try to map packet traces into web pages.

We should denote that throughout this report, we will be using the word ``web pages'' rather than ``websites''.
The reasoning behind this is that a website often consists of multiple HTML documents,
which can result in significantly different traffic traces, depending on which document you load.

The term \textit{``website fingerprinting''} was first mentioned by A. Hintz who performed a simple traffic analysis on Safeweb,
an encrypting web proxy that tried to protect user's privacy \cite{hintz2002fingerprinting}. Although the attack was very simple, it and other earlier
works show the possibility that encrypted channels might still leak information about the URL \cite{hintz2002fingerprinting, wagner1996analysis}.
Later, in 2009, the first fingerprinting attack against Tor was executed by Herrmann et al. using a \textit{Multinomial Naive Bayes} model.
They managed to get a relatively high accuracy for several protocols, such as \textit{OpenSSL} and \textit{OpenVPN}, on a small set of 775 web pages.
However on more specialised anonymization networks, the model only achieved a 2.96\% for Tor, which they said was caused by a suboptimal configuration \cite{herrmann2009website}.

Around the same period Y. Shi et al. performed an attack that specifically focused on anonymity systems such as Tor \cite{shi2009fingerprinting}.
Using a cosine similarity, they achieved around 50\% accuracy on an even smaller dataset of only 20 web pages \cite{shi2009fingerprinting}.
The first real threat however, was by A. Panchenko et al. who used a \textit{Support Vector Classifier} (SVC) on the same dataset of 775 web pages as Herrmann et al.
and got a 54.61\% success rate \cite{herrmann2009website, panchenko1}.

All of the previously mentioned research, except the one done by Panchenko et al. have only considered a \textit{closed-world scenario}.
A closed-world setting means that all of the web pages are known in advance \cite{panchenko1}.
For instance, when Herrmann et al. trained their model on a dataset of 775 web pages, they made the assumption that a client could only visit one of
those web pages and none other.
In an \textit{open-world scenario}, the attacker does not know in advance which URLs the victim might visit.
The most prominent example of this is when the authorities want to monitor which people try to access a set of censored sites \cite{panchenko1}.
In order to achieve this, the models need to be trained on both \textit{monitored} and \textit{unmonited web pages}.

Wang et al. later conducted an attack on Tor using a large open-world dataset \cite{wang_cai_johnson_nithyanand_goldberg_2014}.
Using a novel \textit{k-Nearest Neighbor} (k-NN) classifier with \textit{weight adjustment} on a very large feature set \textit{(3736 features)}.
In addition to getting around 90\% accuracy, they also significantly reduced the time needed for training \cite{wang_cai_johnson_nithyanand_goldberg_2014}.

Using a completely different approach, Hayes et al. extract fingerprints using a \textit{random forests} \cite{kfingerprinting}.
This novel technique involved storing a \textit{fingerprint} as a set of leaves within that forest.
Next, they simply use the \textit{hamming distance} as a distance metric to find the k-nearest neighbors.
If all the labels within those $k$ instances are the same, the model classifies the new instance as the previously mentioned label.
The interesting aspect is that changing the value of $k$ allows them to vary the number of \textit{true positives} (TP) and \textit{false positives} (FP) \cite{kfingerprinting}.

Finally, Panchenko et al. improved upon their previous attack to create one current state-of-the-art methods. They tested their approach on several datasets,
including the one used by Wang et al. on their k-NN attack, where they got around 92\% accuracy.
In an open-world scenario, on the other hand, they got up to 96\% accuracy.

\subsubsection{Automatic Feature Selection}

There are not many works that have examine the use of automatic feature selection techniques in the context of a website fingerprinting attacks.
First, Abe et al. study the use of a \textit{stacked autoencoder} with a \textit{softmax classifier} \cite{deeplearning}.
However, since a stacked autoencoder still requires a fixed-length input, they pad and truncate cells, whose length is shorter or longer than $5000$.
With it, they manage to achieve a $88\%$ accuracy \cite{deeplearning}.

V. Rimmer takes a very similar approach, as she also uses a stacked autoencoder with a softmax classifier \cite{deeplearningthesis}.
But rather than padding and truncating the cells, she transforms the traces into a fixed-length histogram or \textit{wavelength coefficients}.
With this, she manages to achieve a $71\%$ accuracy.

\subsubsection{Defenses}

Not only has there been research regarding different attacks but there are also various works that describe possible defenses.
First of all, Tor already implements \textit{padding}, which means that all packets are padded to a fixed-sized cell of $512$ bytes.
Next, in response to the first attack by Panchenko et al., Tor also supported randomized ordering of HTTP pipelines \cite{panchenko1, kfingerprinting, perry2011experimental}.
Finally, on top of these defenses, fingerprinting on Tor is made more difficult by all of the background noise present.
This is due to the fact that Tor also sends packets for circuit construction or just \textit{SENDME's}, which ensure flow control \cite{panchenko2}.
Although Wang et al. proposed a probabilistic method to remove these \cite{wang_goldberg_2013}, they might still make the classification process slightly more difficult.

Lua et al. designed an application-level defense, that was able to successfully defends against a number of classifiers by modifying packet size, timing of packets, web object size, and
flow size \cite{perry2011experimental}. This is achieved by splitting individual HTTP requests into multiple partial requests, using extra HTTP traffic as a cover and making use of HTTP pipelining \cite{cai_zhang_joshi_johnson_2012}.
Although this has been a relatively effective technique to obfuscate traffic, several attacks have proven that this defense only still does not suffice \cite{cai_zhang_joshi_johnson_2012,wang_cai_johnson_nithyanand_goldberg_2014}.

\textit{BuFLO}, on the other hand, is a \textit{simulatable} defense \cite{wang_cai_johnson_nithyanand_goldberg_2014}, designed by Dyer et al. that performed packet padding and sending data at a constant rate in both directions \cite{dyer2012peek}.
The disadvantage of this method is the high overhead required in order to keep the constant data rate.
Some extensions have been described that try to minimize this overhead such as  Nithyanand's work that uses existing knowledge of a website traces to maintain a high level of security \cite{nithyanand2014glove}.

More recently, Cherubin et al. developed the first website fingerprinting defense on the server side \cite{cherubin2017website}.
This can be particularly interesting for \textit{Tor hidden services} that want to provide, all of their users, the privacy that they require.
The attack uses a technique, called \textit{ALPaCA}, which pads the content of a web page and creates new content to conceal specific features on a network level \cite{cherubin2017website}.

Finally, there are also some other techniques such as \textit{decoy pages} and \textit{traffic morphing} \cite{wright2009traffic,panchenko1}.
Decoy pages or \textit{camouflage} is a very simple technique that involves loading another web page whenever a web page is requested.
This process provides more background noise that makes fingerprinting more difficult \cite{panchenko1}.
Whilst traffic morphing is a slightly more complex technique that changes certain features in the traffic in order to make it appear as if another page is loaded \cite{wright2009traffic}.

\subsubsection{Critical Analysis}

Most attacks, that have been described above, are based on a set of different assumptions.
Here we list these assumptions and see if they are reasonable.

The first one we examine is the open and closed-world scenarios.
One of the main problems with website fingerprinting is the amount of web pages readily available on the web.
An open-world scenario tries to solve this issue by only classifying a small amount of web pages and by labelling the other ones as unmonitored.
However, machine learning theory states that the bigger the world size, the more data is required.
So the small size of the \textit{hypothesis space} compared to our world size, could have a direct impact on the amount of false positives
since the more web pages there are, the higher the probability that one of the traces will be very similar to one in the monitored set.
Therefore, the false positive rates, described in the previously mentioned papers, might be higher in real life \cite{wfpcritique}.

Nonetheless, even if those false positive rates are accurate, a very small amount of false negatives could have a large impact on the classification.
M Perry shows that if the FP rate is as low as $0.2\%$ and just a $100$ page loads, around $18\%$ of the user base would be falsely accused of visiting at least one monitored website.
Or after $1000$ page loads, this percentage increases to around $86\%$ \cite{wfpcritique}.

There are also a variety of different factors that are often not considered such as the rapidly changing nature of some web pages.
Juarez et al. show that it takes around $9$ days for the accuracy to drop from $80\%$ to under $50\%$ \cite{wfpevaluation}.
Additionally, the content of some web pages is dynamic and some of the traces will vary, depending on who visits the website, making the classification for a large set of people difficult.
Not only is dynamic websites an issue but different users will also be using different versions of the Tor Browser Bundle and might load the web page from different locations.
This can decrease the accuracy with $70\%$ and $50\%$ respectively \cite{wfpevaluation}.
On top of this, we also need to consider multi-tab browsing, where a client might be loading multiple web pages at the same time.
Although some papers consider this \cite{naivebayes}, most assume that the attacker know where the trace of a single page starts and ends.

\subsection{Deep Learning and Automatic Feature Selection}

In the following section, we will give a very short introduction to deep learning and describe some of the deep learning solutions that allow us to perform feature extraction.
We start by introducing deep learning by exploring \textit{artificial neural networks} and \textit{stacked autoencoders}.
Then we move on to \textit{recurrent neural networks} and \textit{sequence-to-sequence models}.
Finally, we describe some of the issues with deep learning, such as the \textit{vanishing gradient problem}.
All of these explanations assume some familiarity with neural networks and don't go into depth, as that is outside the scope of this paper.

Machine learning models basically take some value as its input and output a value, whilst trying to minimize some sort of error.
All of the learning models that we explore below are forms of \textit{supervised learning}.
This means that we know the expected output and minimize the error between the actual output and the expected output.

\subsubsection{Artificial Neural Networks}

\textit{Artificial neural networks} consist of a network of nodes, called \textit{neurons}.
These neurons are named and modeled after their biological counterparts.
One of the simplest ones, is called a \textit{perceptron}, which consists of a set of \textit{binary inputs}, \textit{weights} and an \textit{activation function}.
Hence, essentially it weights different evidence by assigning a different weight to every input.
Next, the output of the neuron can be calculated as follows:

$$\text{output} = f(\sum_{i} w_i x_i)$$

\newpage

\begin{figure}[h]
  \centering
  \includegraphics[width=0.4\textwidth]{perceptron}
  \caption{Model of a perceptron with three inputs.}
  \label{fig:perceptron}
\end{figure}

This function $f$ represents the \textit{activation function}.
Essentially, the activation function expresses the idea that a neuron can `fire' after the sum of the inputs exceeds a certain threshold.
There are certain different functions such as the \textit{step function}, \textit{sigmoid function} and the \textit{tanh function},
which are all outlined in figure \ref{fig:activation-functions}.

\begin{figure}[h]
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tikzpicture}
      \draw[->] (-3, 0) -- (3, 0) node[right] {$x$};
      \draw[->] (-3, 0) -- (-3, 3) node[above] {$y$};
      \draw[dotted] (-3, 1.5) -- (3, 1.5);
      \draw[blue] (-1.5, 0) -- (0, 0);
      \draw[blue] (0, 0) -- (0, 3);
      \draw[blue] (0, 3) -- (3, 3);
    \end{tikzpicture}
    }
    \caption{The step function.}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tikzpicture}
      \draw[->] (-3, 0) -- (3, 0) node[right] {$x$};
      \draw[->] (-3, 0) -- (-3, 3) node[above] {$y$};
      \draw[dotted] (-3, 1.5) -- (3, 1.5);
      \draw[yscale=3,domain=-3:3,smooth,variable=\x,blue] plot ({\x},{1 / (1 + (e^(-\x)))});
    \end{tikzpicture}
    }
    \caption{The sigmoid function.}
  \end{subfigure}
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tikzpicture}
      \draw[->] (-3, 0) -- (3, 0) node[right] {$x$};
      \draw[->] (-3, -1.5) -- (-3, 1.5) node[above] {$y$};
      \draw[yscale=1.5,domain=-3:3,smooth,variable=\x,blue] plot ({\x},{(2 / (1 + (e^(-2 * \x)))) - 1});
    \end{tikzpicture}
    }
    \caption{The tanh function.}
  \end{subfigure}
  \caption{Examples of different activation functions}

\label{fig:activation-functions}
\end{figure}

Now to learn a function, it adapts the weight $w_i$ such that it minimizes the error between the predicted and the expected output.
In order to achieve this, we need some manner of quantifying the error, called a \textit{loss function}.
The most commonly used ones are the \textit{mean squared error} ($\text{MSE} = (x - x')^2$) and \textit{absolute loss} ($\text{AL} = | x - x' |$) \cite{nielsen_2017}.
There are may other cost functions such as \textit{cross-entropy}, but they are not often used for the models that will be described below.

To build a neural network, several of these perceptrons are connected together.
The most standard network is a \textit{multilayer perceptron}, also called a \textit{feedforward neural net}.
This specific network, as can be seen in figure \ref{fig:feedforward}, consists of an \textit{input layer}, one or more \textit{hidden layers} and an \textit{output layer}.
All of these layers have an arbitrary number of neurons and the connections between these neurons can only go from left to right and can never form a loop.
It is known that these kinds of networks can learn to approximate any function \cite{valiant2014learning}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.4\textwidth]{feedforward}
  \caption{Example of an feedforward neural network with one hidden layer}
  \label{fig:feedforward}
\end{figure}

Now that we know how to construct these networks, we still need to manage to assign the appropriate weights to every connection such that the loss function is minimized.
There weights can be learnt by using an algorithm, called \textit{backpropagation}.
The optimization process usually starts with initializing all of the weights with a random value and then running backpropagation, which is structured as follows \cite{nielsen_2017}:
\begin{enumerate}
  \item Compute the outputs, given a certain input \textit{(feedforward pass)}.
  \item Calculate the error vector.
  \item Backpropagate the error by computing the differences between the expected output and the actual output, starting at the output layer and working towards the input layer.
  \item Compute the partial derivatives for the weights.
  \item Adjust the weights by subtracting these derivatives, multiplied by the \textit{learning rate}.
\end{enumerate}

The learning rate is essentially a hyperparameter to the model that defines how fast the network learns.
If its value is high, the model learns quickly and if the value is low, the model learns more slowly but the learning process will be more accurate.
The propagation process is also often done in \textit{batches}, which means that you calculate the propagations of a fixed amount of input vectors and only once this has finished, the weighs are changed.
The size of these batches is a hyperparameter of the model.

\subsubsection{Stacked autoencoder}

These feedforward neural net can be used to perform feature selection, by using a network called an \textit{autoencoder}.
This network tries to learn the \textit{identity function} $f(x) \approx x$ when the number of neurons in the hidden layer is smaller than the ones in the input and output layers.
Hence, essentially the network is trying to learn to learn how to compress the initial feature vector \cite{authoencoders}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.4\textwidth]{autoencoder}
  \caption{Example of a simple autoencoder}
  \label{fig:feedforward}
\end{figure}

In order to learn an even more compressed representation of the input, multiple layers are often introduces.
Where each hidden layer contains even less nodes than the previous one.


\subsubsection{Recurrent Neural Networks}

\subsubsection{Sequence-to-Sequence Model}

\subsubsection{The Vanishing Gradient Problem}

\subsection{Software Libraries}
