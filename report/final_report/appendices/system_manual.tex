% TODO: Remove
\addbibresource{../report.bib}

\chapter{System Manual}

\begingroup

\renewcommand{\thesubsection}{\arabic{subsection}}

\renewcommand{\addcontentsline}[3]{}% Do nothing

Here, we outline the technical details of the project such that the development of the system could be continued by a third party.

First, we will look at the tools required to run the system then we will look at the overall system and how specific modules connect together.
Finally, we explain the specific components and outline how you can contribute to this project.

All of the code is hosted in a private repository on Github.
If given access, it can be cloned from the following url (https://github.com/AxelGoetz/website-fingerprinting.git).

\subsection{Tools Required and Installation Instructions}

Most of the project has been written in Python, more specifically, everything has been designed and tested with version 3.6.
Our Travis build has also been configured to run all of the tests with Python 3.5, which means that we still get notified if anything breaks under a specific Python version.
Some of the code has also been written in Golang, those parts have been adapted from an implementation of Wang et al.'s kNN attack for performance reasons \cite{wang_cai_johnson_nithyanand_goldberg_2014,gokNN}.

Next, after the correct version of Python and Golang are installed, we also require a \textit{virtual environment} to manage all of our python dependencies.
If you have \texttt{pip} on your system, this can easily installed as follows:

\begin{lstlisting}[language=Bash]
pip install virtualenv
\end{lstlisting}

After the virtual environment is installed, go to the project directory and run the following commands to first create the environment and then activate it.

\begin{lstlisting}[language=Bash]
virtualenv venv
source venv/bin/activate
\end{lstlisting}

At any time, you can go out of the virtual environment by running \texttt{deactivate}.
After you are in the environment, we need to install a list of dependencies, which can be found in the \texttt{requirements.txt} file.
This can be done by running:
\begin{lstlisting}[language=Bash]
pip install -r requirements.txt
\end{lstlisting}

This will install a list of dependencies but the main ones are \textit{Tensorflow v1.1}, \textit{numpy}, \textit{sklearn} and \textit{scipy}.
There are a couple others but they are not used for major components.

If you plan to use the GPU support on Tensorflow, there are a couple more steps that need to be taken such as installing \textit{CUDA 8} and \textit{cuDNN v5.1}.
These instructions can be found on the Tensorflow site\footnote{https://www.tensorflow.org/install}.
Our project relied on an Amazon EC2 p2.xlarge with one NVIDIA K80 GPU but the code can be run on any GPU card with CUDA compute capability 3.0 or higher \cite{tensorflow}.

\newpage

In order to run the experiments, the datasets will have to be downloaded next.
The main dataset used is \texttt{GRESCHBACH}\footnote{https://nymity.ch/tor-dns/\#data} but we also use \texttt{WANG14}\footnote{https://cs.uwaterloo.ca/~t55wang/wf.html}.
These should be put in a data folder in the main directory where the directory containing the \texttt{GRESCHBACH} data, should be renamed to \texttt{cells} and the \texttt{WANG14} data to \texttt{WANG14\_cells}.

\subsection{System Overview}

Figure \ref{fig:code-structure} already shows the overall structure of the and how different components interact.
Next, in section \ref{sec:code-structure} we also explain what the individual sections do.
Hence, here we describe the same using a \textit{directory tree}.

\dirtree{%
.1 /.
.2 attacks - Contains the code for all of the classifiers.
.2 data.
.3 cells - All of the individual cell files from the GRESCHBACH dataset.
.2 feature\_extraction - All of the code to extract the hand-picked features from different models.
.2 feature\_generation - Perform automatic feature generation.
.3 new\_model - The Tensorflow implementation of the sequence-to-sequence model.
.3 train\_model - Used to train the model.
.3 feature\_extraction - After the model is trained, can be used to extract the features.
.2 report - The latex and pdf files for this report.
.2 run\_models - Provides the infrastructure to run a specific attack in the attacks directory.
.2 tests - The unit tests to test everything.
.2 gitignore.
.2 travis.
.2 LICENSE.
.2 README - More information on the project and how to install/run everything.
.2 requirements - The python packages required.
}

\subsection{Components}

Here how the individual components work and how to potentially extend them.

\subsubsection{Attacks}

This components implements all of the classifiers that are used to compare the hand-picked features with the automatically generated ones.
Each of these classes needs to implement the interface, which has a \texttt{fit} and \texttt{predict} method.
This is similar to the machine learning models provided in \textit{sklearn} \cite{scikitlearn}.
The fit method takes an $X$ and $y$ input and changes its internal structure such that it minimizes the error.
The predict method on the other hand just takes $X$ as its input and returns a vector $y$ of what it predicts the input represents.

The models should also have a \texttt{is\_multiclass} flag, which represents the fact whether the classifier performs a binary or multiclass classification task.

\subsubsection{Feature Extraction}

All of the logic to extract the hand-picked features for different attacks is in this module.
If a new attack is added, a new file should be created in this directory, with the code to extract all the required features from a given trace.
Next, this function needs to be added to the list in the \texttt{feature\_extraction.py} file.
This file essentially goes over all the traces within the \texttt{data/cells} directory and stores the extracted features within the \texttt{data} directory.

\subsubsection{Feature Generation}

This is one of the main components of this work, containing the code to automatically generate features.
The model is defined in the \texttt{new\_model.py} file, where you can construct the sequence-to-sequence and train it.
The main infrastructure to actually import the data, do all of the preprocessing and train the model is defined within \texttt{train\_model.py}.

After every epoch, the infrastructure will save the computational graph such that training can be continued even if it is interrupted.

Finally, all of the logic to actually extract the features is in the \texttt{feature\_extraction.py} file, which again stores the fingerprints in the \texttt{data} directory.

If you wish to implement a new model, it just needs to implement two main functions such that it can be used by the rest of the infrastructure.
These are \texttt{train\_on\_copy\_task} and \texttt{get\_vector\_representations}, which both take some data as their input and either train the model or extract features.

\subsubsection{Run Models}

All of the infrastructure to actually run the classifiers is defined within this module.
First, it defines the logic to preprocess all of the necessary data and perform the \textit{k-fold validation}.
Next, it also defines all of the scoring methods and how to actually run the models.
The main logic is actually in the \texttt{run\_models.py} file, which allows the user to tune certain parameters such that they can run different models.

Whenever a new classifier is added to the \texttt{attacks} directory, it should also be added within the \texttt{run\_models.py} file such that a user knows that it can be run.

\subsubsection{Unit Tests}

For unit testing, we use the standard \texttt{unittest} module, which is very simple to use.
To create more tests, create a new file in the \texttt{tests} directory, which starts with test and then the name of what you will be testing.
Next, create a class within that file, which extends the \texttt{unittest.TestCase} class and add the methods of what you would like to test.

Then to run all of the unit tests within the \texttt{tests} directory, simply run:
\begin{lstlisting}[language=Bash]
python -m unittest discover
\end{lstlisting}

\newpage

\subsection{Contributing}

There are a variety of different extensions possible, some of which are outlined in section \ref{sec:future-works}.
If you decide to implement one of these, we use a very standard git workflow so if you would like to contribute, follow these steps:

\begin{enumerate}
  \item Fork the project repo.
  \item Create a branch with the name of the particular improvement/extension that you will be working on.
  \item After you are done, make sure that you run all of the tests and check if everything still works.
  \item Submit a pull request from your branch to the master branch and make sure all of the tests pass on Travis.
\end{enumerate}

If you discover an issue or want to work on an extension, please create an issue on our Github issues page to let people know that you are working on this particular extension.

\endgroup
